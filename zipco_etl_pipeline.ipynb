{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b67a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import psycopg2\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f3199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://realty-mole-property-api.p.rapidapi.com/randomProperties\"\n",
    "\n",
    "querystring = {\"limit\":\"100000\"}\n",
    "\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": \"64114f9223mshf6ee7f915c727eep1a5d9djsnef3a9270cef8\",\n",
    "\t\"x-rapidapi-host\": \"realty-mole-property-api.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "# print(response.json())\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# save data to json file\n",
    "filename = 'PropertyRecords.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37a3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into a DataFrame\n",
    "propertyrecords_df = pd.read_json('PropertyRecords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f764b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation layer\n",
    "# 1st step - convert dictionary column to string\n",
    "propertyrecords_df['features'] = propertyrecords_df['features'].apply(json.dumps)\n",
    "propertyrecords_df['owner'] = propertyrecords_df['owner'].apply(json.dumps)\n",
    "propertyrecords_df['ownerOccupied'] = propertyrecords_df['ownerOccupied'].apply(json.dumps)\n",
    "\n",
    "# 2nd step - replace NaN values with appropriate defaults or remove  row/columns as necessary\n",
    "propertyrecords_df.fillna({\n",
    "    'assessorID': 'Unknown',\n",
    "    'legalDescription': 'Not available',\n",
    "    'squareFootage': 0,\n",
    "    'subdivision': 'Not available',\n",
    "    'yearBuilt': 0,\n",
    "    'bathrooms': 0,\n",
    "    'lotSize': 0,\n",
    "    'propertyType': 'Unknown',\n",
    "    'lastSalePrice': 0,\n",
    "    'lastSaleDate': 'Not available',\n",
    "    'features': 'None',\n",
    "    'taxAssessment': 'Not available',\n",
    "    'owner': 'Unknown',\n",
    "    'propertyTaxes': 'Not available',\n",
    "    'bedrooms': 0,\n",
    "    'ownerOccupied': 0,\n",
    "    'zoning': 'Unknown',\n",
    "    'addressLine2': 'Not available',\n",
    "    'formattedAddres': 'Not available',\n",
    "    'county': 'Not available',\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37732bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to datetime with coercion of invalid entries\n",
    "propertyrecords_df['lastSaleDate'] = pd.to_datetime(\n",
    "    propertyrecords_df['lastSaleDate'], \n",
    "    errors='coerce'  # Converts invalid formats to NaT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc806b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = propertyrecords_df[['formattedAddress', 'city', 'state', 'zipCode', 'county', 'subdivision', 'longitude', 'latitude', 'zoning']].copy().drop_duplicates().reset_index(drop=True)\n",
    "location['location_id'] =range(1, len(location) + 1)\n",
    "location = location[['location_id', 'formattedAddress', 'city', 'state', 'zipCode', 'county', 'subdivision', 'longitude', 'latitude', 'zoning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90147e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "property = propertyrecords_df[['propertyType', 'bedrooms', 'bathrooms', 'squareFootage', 'yearBuilt', 'legalDescription', 'lastSaleDate', 'ownerOccupied', 'lotSize']].copy().drop_duplicates().reset_index(drop=True)\n",
    "property['property_id'] =range(1, len(property) + 1)\n",
    "property = property[['property_id', 'propertyType', 'bedrooms', 'bathrooms', 'squareFootage', 'yearBuilt', 'legalDescription', 'lastSaleDate', 'ownerOccupied', 'lotSize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446b2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = propertyrecords_df[['lastSaleDate', 'lastSalePrice']].copy().drop_duplicates().reset_index(drop=True)\n",
    "sales['sales_id'] =range(1, len(sales) + 1)\n",
    "sales = sales[['sales_id', 'lastSaleDate', 'lastSalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262b2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge operation to create the propertyrecords_df\n",
    "propertyrecords_df = propertyrecords_df.merge(location, on=['formattedAddress', 'city', 'state', 'zipCode', 'county', 'subdivision', 'longitude', 'latitude', 'zoning'], how ='left') \\\n",
    "                            .merge(property, on=['propertyType', 'bedrooms', 'bathrooms', 'squareFootage', 'yearBuilt', 'legalDescription', 'lastSaleDate', 'ownerOccupied', 'lotSize'], how='left') \\\n",
    "                            .merge(sales, on=['lastSaleDate', 'lastSalePrice'], how='left') \\\n",
    "                            [['location_id', 'property_id', 'sales_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d8a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a date dimension table\n",
    "start_date = datetime(2020, 1, 1)\n",
    "current_date = datetime(2090, 12, 31)\n",
    "\n",
    "# calculate the number of days between start date and current date\n",
    "num_days = (current_date - start_date).days\n",
    "\n",
    "# Generate a list of dates from start date to current date\n",
    "date_list = [start_date + timedelta(days=x) for x in range(num_days + 1)]\n",
    "\n",
    "#Ensure date_id matches the length of date_list\n",
    "date = {'date_id': [x for x in range(1, len(date_list) + 1)], 'date': date_list}\n",
    "\n",
    "# Create DataFrame\n",
    "date_dim = pd.DataFrame(date)\n",
    "date_dim['Year'] = date_dim['date'].dt.year\n",
    "date_dim['Month'] = date_dim['date'].dt.month\n",
    "date_dim['Day'] = date_dim['date'].dt.day\n",
    "date_dim['date'] = pd.to_datetime(date_dim['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac326eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link Property table with date\n",
    "property['lastSaleDate'] = pd.to_datetime(property['lastSaleDate']).dt.date\n",
    "property = property.merge(date_dim, left_on='lastSaleDate', right_on='date', how='inner') \\\n",
    "                    .rename(columns={'date_id':'lastSaleDate_ID'}) \\\n",
    "                    .reset_index(drop=True) \\\n",
    "                    [['property_id', 'propertyType', 'bedrooms', 'bathrooms', 'squareFootage', 'yearBuilt', 'legalDescription', 'lastSaleDate_ID', 'ownerOccupied', 'lotSize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c30d345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link sales table with date\n",
    "sales['lastSaleDate'] = pd.to_datetime(sales['lastSaleDate']).dt.date\n",
    "sales = sales.merge(date_dim, left_on='lastSaleDate', right_on='date', how='inner') \\\n",
    "                    .rename(columns={'date_id':'lastSaleDate_ID'}) \\\n",
    "                    .reset_index(drop=True) \\\n",
    "                    [['sales_id', 'lastSaleDate_ID', 'lastSalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f98de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to directory\n",
    "location.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\cleandata\\location.csv', index=False)\n",
    "property.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\cleandata\\property.csv', index=False)\n",
    "sales.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\cleandata\\sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f31f0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propety DWH Model\n",
    "property_dim = property[['property_id', 'propertyType']].copy().drop_duplicates().reset_index(drop=True)\n",
    "sales_dim = sales[['sales_id', 'lastSaleDate_ID', 'lastSalePrice']].copy().drop_duplicates().reset_index(drop=True)\n",
    "location_dim = location[['location_id', 'formattedAddress', 'city', 'state']].copy().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "property_fact_table = propertyrecords_df.merge(property, on='property_id', how='inner') \\\n",
    "                                        .merge(sales, on='sales_id', how='inner') \\\n",
    "                                        [['location_id', 'property_id', 'sales_id']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e800529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a date dimension table\n",
    "start_date = datetime(2020, 1, 1)\n",
    "current_date = datetime(2090, 12, 31)\n",
    "\n",
    "# calculate the number of days between start date and current date\n",
    "num_days = (current_date - start_date).days\n",
    "\n",
    "# Generate a list of dates from start date to current date\n",
    "date_list = [start_date + timedelta(days=x) for x in range(num_days + 1)]\n",
    "\n",
    "#Ensure date_id matches the length of date_list\n",
    "date = {'date_id': [x for x in range(1, len(date_list) + 1)], 'date': date_list}\n",
    "\n",
    "# Create DataFrame\n",
    "date_dim = pd.DataFrame(date)\n",
    "date_dim['Year'] = date_dim['date'].dt.year\n",
    "date_dim['Month'] = date_dim['date'].dt.month\n",
    "date_dim['Day'] = date_dim['date'].dt.day\n",
    "date_dim['date'] = pd.to_datetime(date_dim['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f477fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to memory\n",
    "property_dim.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\transaction_dwh\\property_dim.csv', index=False)\n",
    "sales_dim.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\transaction_dwh\\sales_dim.csv', index=False)\n",
    "location_dim.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\transaction_dwh\\location_dim.csv', index=False)\n",
    "property_fact_table.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\transaction_dwh\\property_fact_table.csv', index=False)\n",
    "date_dim.to_csv(r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\transaction_dwh\\date_dim.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e525ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Layer\n",
    "# develop a function to connect to pgadmin\n",
    "\n",
    "def get_db_connection():\n",
    "    connection = psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        database = 'zipco_agency',\n",
    "        user = 'postgres',\n",
    "        password = 'Favour@8282'\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "conn = get_db_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8390bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create schema and tables\n",
    "def create_tables():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    create_table_query = '''\n",
    "    CREATE SCHEMA IF NOT EXISTS zipco;\n",
    "\n",
    "    DROP TABLE IF EXISTS zipco.property CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.location CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.sales CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.date_dim CASCADE;\n",
    "    DROP TABLE IF EXISTS zipco.property_fact_table CASCADE;\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.date_dim (\n",
    "        date_id SERIAL PRIMARY KEY,\n",
    "        date VARCHAR(10000),\n",
    "        Year INTEGER,\n",
    "        Month INTEGER,\n",
    "        Day INTEGER\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.property (\n",
    "        property_id SERIAL PRIMARY KEY,\n",
    "        propertyType VARCHAR(255),\n",
    "        bedrooms FLOAT,\n",
    "        bathrooms FLOAT,\n",
    "        squareFootage FLOAT,\n",
    "        yearBuilt FLOAT,\n",
    "        legalDescription VARCHAR(255),\n",
    "        lastSaleDate_ID INTEGER,\n",
    "        ownerOccupied VARCHAR(50),\n",
    "        lotSize FLOAT,\n",
    "        FOREIGN KEY (lastSaleDate_ID) REFERENCES zipco.date_dim(date_id)\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.location (\n",
    "        location_id SERIAL PRIMARY KEY,\n",
    "        formattedAddress VARCHAR(255),\n",
    "        city VARCHAR(100),\n",
    "        state VARCHAR(100),\n",
    "        zipcode INTEGER,\n",
    "        county VARCHAR(100),\n",
    "        subdivision VARCHAR(100),\n",
    "        longitude FLOAT,\n",
    "        latitude FLOAT,\n",
    "        zoning VARCHAR(100)\n",
    "    );\n",
    "    \n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.sales (\n",
    "        sales_id SERIAL PRIMARY KEY,\n",
    "        lastsaleDate_ID INTEGER,\n",
    "        lastsalePrice VARCHAR(255),\n",
    "        FOREIGN KEY (lastSaleDate_ID) REFERENCES zipco.date_dim(date_id)\n",
    "        \n",
    "    );\n",
    "    \n",
    "    CREATE TABLE IF NOT EXISTS zipco.property_fact_table (\n",
    "        location_id INTEGER,\n",
    "        property_id INTEGER,\n",
    "        sales_id INTEGER,\n",
    "        FOREIGN KEY (location_id) REFERENCES zipco.location(location_id),\n",
    "        FOREIGN KEY (property_id) REFERENCES zipco.property(property_id),\n",
    "        FOREIGN KEY (sales_id) REFERENCES zipco.sales(sales_id)\n",
    "    );\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit() \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    \n",
    "create_tables()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "897d021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to load the csv data into the database\n",
    "\n",
    "def load_data_from_csv_to_table(csv_path, table_name):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_path, 'r', encoding = 'utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader) # Skip the header row\n",
    "        for row in reader:\n",
    "            placeholders = ', '.join(['%s'] * len(row))\n",
    "            query = f'INSERT INTO {table_name} VALUES ({placeholders});'\n",
    "            cursor.execute(query, row)\n",
    "    conn.commit() \n",
    "    cursor.close()\n",
    "    conn.close()  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8471b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_csv_path = r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\cleandata\\location.csv'\n",
    "load_data_from_csv_to_table(location_csv_path, 'zipco.location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eab070c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dim_csv_path = r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\transaction_dwh\\date_dim.csv'\n",
    "load_data_from_csv_to_table(date_dim_csv_path, 'zipco.date_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce8ec969",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_csv_path = r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\cleandata\\sales.csv'\n",
    "load_data_from_csv_to_table(sales_csv_path, 'zipco.sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc080f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_csv_path = r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\cleandata\\property.csv'\n",
    "load_data_from_csv_to_table(property_csv_path, 'zipco.property')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aaebdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_fact_table_dim_csv_path = r'C:\\Users\\Acer\\OneDrive\\Desktop\\zipco_agency\\zipco\\dataset\\transaction_dwh\\property_fact_table.csv'\n",
    "load_data_from_csv_to_table(property_fact_table_dim_csv_path, 'zipco.property_fact_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50feff71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
